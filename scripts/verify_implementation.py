#!/usr/bin/env python3
"""
Comprehensive parser for Ethiopian Orthodox/Catholic Bible (72 books)
Tests and verifies all books are properly embedded
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any
import sys

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from config.settings import settings, RAW_DATA_DIR, PROCESSED_DATA_DIR

class EthiopianBibleParser:
    """
    Parses Ethiopian Orthodox/Catholic Bible with all 72 books
    """
    
    def __init__(self):
        # Complete list of 72 books in Ethiopian Orthodox Bible
        self.all_72_books = {
            # Old Testament (46 books)
            "old_testament": [
                "áŠ¦áˆªá‰µ á‹˜ááŒ¥áˆ¨á‰µ", "áŠ¦áˆªá‰µ á‹˜áŒ¸áŠ á‰µ", "áŠ¦áˆªá‰µ á‹˜áˆŒá‹‹á‹á‹«áŠ•", "áŠ¦áˆªá‰µ á‹˜áŠáˆá‰", "áŠ¦áˆªá‰µ á‹˜á‹³áŒáˆ",
                "áˆ˜áŒ½áˆáˆ áŠ¢á‹«áˆ± á‹ˆáˆá‹° áŠá‹Œ", "áˆ˜áŒ½áˆáˆ áˆ˜áˆ£ááŠ•á‰µ", "áˆ˜áŒ½áˆáˆ áˆ©á‰µ", 
                "áˆ˜áŒ½áˆáˆ áˆ³áˆ™áŠ¤áˆ á‰€á‹³áˆ›á‹Š", "áˆ˜áŒ½áˆáˆ áˆ³áˆ™áŠ¤áˆ áŠ«áˆá‹•",
                "áˆ˜áŒ½áˆáˆ áŠáŒˆáˆ¥á‰µ á‰€á‹³áˆ›á‹Š", "áˆ˜áŒ½áˆáˆ áŠáŒˆáˆ¥á‰µ áŠ«áˆá‹•",
                "áˆ˜áŒ½áˆáˆ á‹œáŠ“ áˆ˜á‹‹á‹•áˆ á‰€á‹³áˆ›á‹Š", "áˆ˜áŒ½áˆáˆ á‹œáŠ“ áˆ˜á‹‹á‹•áˆ áŠ«áˆá‹•",
                "áˆ˜áŒ½áˆáˆ á‹•á‹áˆ«", "áˆ˜áŒ½áˆáˆ áŠáˆ…áˆá‹«", "áˆ˜áŒ½áˆáˆ áŠ áˆµá‰´áˆ­", "áˆ˜áŒ½áˆáˆ áŠ¢á‹®á‰¥",
                "áˆ˜á‹áˆ™áˆ¨ á‹³á‹Šá‰µ", "áˆ˜áŒ½áˆáˆ áˆáˆ³áˆŒ", "áˆ˜áŒ½áˆáˆ áˆ˜áŠ­á‰¥á‰¥", "áˆ˜áŠƒáˆá‹¨ áˆ˜áŠƒáˆá‹­ á‹˜áˆ°áˆáˆáŠ•",
                "á‰µáŠ•á‰¢á‰° áŠ¢áˆ³á‹­á‹«áˆµ", "á‰µáŠ•á‰¢á‰° áŠ¤áˆ­áˆá‹«áˆµ", "á‹áŠ…á‹á‰µ áŠ¤áˆ­áˆá‹«áˆµ", "á‰µáŠ•á‰¢á‰° áˆ•á‹á‰…áŠ¤áˆ",
                "á‰µáŠ•á‰¢á‰° á‹³áŠ•áŠ¤áˆ", "á‰µáŠ•á‰¢á‰° áˆ†áˆ´á‹•", "á‰µáŠ•á‰¢á‰° áŠ¢á‹®áŠ¤áˆ", "á‰µáŠ•á‰¢á‰° áŠ áˆáŒ½",
                "á‰µáŠ•á‰¢á‰° áŠ á‰¥á‹µá‹©", "á‰µáŠ•á‰¢á‰° á‹®áŠ“áˆµ", "á‰µáŠ•á‰¢á‰° áˆšáŠ­á‹«áˆµ", "á‰µáŠ•á‰¢á‰° áŠ“áˆ†áˆ",
                "á‰µáŠ•á‰¢á‰° á‹•áŠ•á‰£á‰†áˆ", "á‰µáŠ•á‰¢á‰° áˆ¶ááŠ•á‹«áˆµ", "á‰µáŠ•á‰¢á‰° áŠƒáŒŒ", "á‰µáŠ•á‰¢á‰° á‹˜áŠ«áˆ­á‹«áˆµ", "á‰µáŠ•á‰¢á‰° áˆšáˆ‹áŠ­",
                "áˆ˜áŒ½áˆáˆ áˆ™áŠ­á‹«áˆµ", "áˆ˜áŒ½áˆáˆ áŠ¤áŠªáˆŒáˆ²á‹«áˆµá‰²áŠ¨áˆµ", "á‰µáŠ•á‰¢á‰° á‰£áˆ©áŠ­", "áˆ˜áŒ½áˆáˆ á‰¶á‰¢á‰µ",
                "áˆ˜áŒ½áˆáˆ áŠ¢á‹©á‹²á‰µ", "áˆ˜áŒ½áˆáˆ áŠ áˆµá‰´áˆ­ áŒáˆªáŠ­", "áˆ˜áŒ½áˆáˆ á‹˜áŠµáˆáŠ“ áˆ•áŒ"
            ],
            # New Testament (26 books) 
            "new_testament": [
                "á‹¨áˆ›á‰´á‹áˆµ á‹ˆáŠ•áŒŒáˆ", "á‹¨áˆ›áˆ­á‰†áˆµ á‹ˆáŠ•áŒŒáˆ", "á‹¨áˆ‰á‰ƒáˆµ á‹ˆáŠ•áŒŒáˆ", "á‹¨á‹®áˆáŠ•áˆµ á‹ˆáŠ•áŒŒáˆ",
                "á‹¨áˆá‹‹áˆ­á‹«á‰µ áˆ¥áˆ«", "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áˆ®áˆœ", 
                "á‹¨áŒ³á‹áˆáˆµ á‰€á‹³áˆ›á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰†áˆ®áŠ•á‰¶áˆµ", "á‹¨áŒ³á‹áˆáˆµ áŠ«áˆá‹• áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰†áˆ®áŠ•á‰¶áˆµ",
                "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŒˆáˆ‹á‰µá‹«", "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŠ¤áŒáˆ¶áŠ•",
                "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŠáˆŠáŒµáˆµá‹©áˆµ", "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰†áˆ‹áˆµá‹­áˆµ",
                "á‹¨áŒ³á‹áˆáˆµ á‰€á‹³áˆ›á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰°áˆ°áˆáŠ•á‰„", "á‹¨áŒ³á‹áˆáˆµ áŠ«áˆá‹• áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰°áˆ°áˆáŠ•á‰„",
                "á‹¨áŒ³á‹áˆáˆµ á‰€á‹³áˆ›á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŒ¢áˆá‰´á‹áˆµ", "á‹¨áŒ³á‹áˆáˆµ áŠ«áˆá‹• áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŒ¢áˆá‰´á‹áˆµ",
                "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° á‰²á‰¶áˆµ", "á‹¨áŒ³á‹áˆáˆµ áˆ˜áˆáŠ¥áŠ­á‰µ á‹ˆá‹° áŠáˆáˆáŠ•áˆµ",
                "á‹¨áŠ¥á‰¥áˆ«á‹á‹«áŠ• áˆ˜áˆáŠ¥áŠ­á‰µ", "á‹¨á‹«á‹•á‰†á‰¥ áˆ˜áˆáŠ¥áŠ­á‰µ", 
                "á‹¨áŒ´áŒ¥áˆ®áˆµ á‰€á‹³áˆ›á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ", "á‹¨áŒ´áŒ¥áˆ®áˆµ áŠ«áˆá‹• áˆ˜áˆáŠ¥áŠ­á‰µ",
                "á‹¨á‹®áˆáŠ•áˆµ á‰€á‹³áˆ›á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ", "á‹¨á‹®áˆáŠ•áˆµ áŠ«áˆá‹• áˆ˜áˆáŠ¥áŠ­á‰µ", "á‹¨á‹®áˆáŠ•áˆµ áˆ£áˆáˆ³á‹Š áˆ˜áˆáŠ¥áŠ­á‰µ",
                "á‹¨á‹­áˆá‹³ áˆ˜áˆáŠ¥áŠ­á‰µ", "á‹¨á‹®áˆáŠ•áˆµ áˆ«áŠ¥á‹­"
            ]
        }
        
    def analyze_bible_structure(self, file_path: str) -> Dict[str, Any]:
        """Analyze the structure of the Amharic Bible file"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Look for book titles
        found_books = []
        book_positions = {}
        
        for testament, books in self.all_72_books.items():
            for book in books:
                # Find book in text
                pattern = rf'\b{re.escape(book)}\b'
                matches = list(re.finditer(pattern, content))
                
                if matches:
                    found_books.append(book)
                    book_positions[book] = {
                        "testament": testament,
                        "positions": [m.start() for m in matches],
                        "count": len(matches)
                    }
        
        return {
            "total_books_found": len(found_books),
            "found_books": found_books,
            "book_positions": book_positions,
            "total_expected": 72,
            "coverage": len(found_books) / 72 * 100
        }
    
    def extract_all_books(self, file_path: str) -> Dict[str, Dict[str, str]]:
        """Extract all 72 books with their chapters"""
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        extracted_books = {}
        
        # More sophisticated parsing
        for testament, books in self.all_72_books.items():
            for book in books:
                chapters = self._extract_book_chapters(content, book)
                if chapters:
                    extracted_books[book] = chapters
        
        return extracted_books
    
    def _extract_book_chapters(self, content: str, book_name: str) -> Dict[str, str]:
        """Extract chapters for a specific book"""
        
        # Find book start
        book_pattern = rf'\b{re.escape(book_name)}\b'
        book_match = re.search(book_pattern, content)
        
        if not book_match:
            return {}
        
        book_start = book_match.end()
        
        # Find next book to determine end boundary
        next_book_start = len(content)
        for testament, books in self.all_72_books.items():
            for other_book in books:
                if other_book != book_name:
                    other_match = re.search(rf'\b{re.escape(other_book)}\b', content[book_start:])
                    if other_match:
                        pos = book_start + other_match.start()
                        if pos < next_book_start:
                            next_book_start = pos
        
        book_content = content[book_start:next_book_start]
        
        # Extract chapters
        chapters = {}
        chapter_pattern = r'áˆá‹•áˆ«á\s+(\d+|[á©-á¼]+)'
        chapter_matches = list(re.finditer(chapter_pattern, book_content))
        
        for i, match in enumerate(chapter_matches):
            chapter_num = match.group(1)
            chapter_start = match.end()
            
            # Find end of chapter
            if i + 1 < len(chapter_matches):
                chapter_end = chapter_matches[i + 1].start()
            else:
                chapter_end = len(book_content)
            
            chapter_text = book_content[chapter_start:chapter_end].strip()
            if chapter_text:
                chapters[f"chapter_{chapter_num}"] = chapter_text
        
        return chapters

def verify_implementation():
    """Verify the complete implementation works locally"""
    
    print("ğŸ” Verifying Amharic Bible Embeddings Implementation")
    print("=" * 60)
    
    # Check project structure
    project_root = Path("/Users/mekdesyared/Embedding/amharic-bible-embeddings")
    
    required_files = [
        ".env.example",
        "requirements.txt", 
        "config/settings.py",
        "config/llm_config.py",
        "src/preprocessing/amharic_cleaner.py",
        "src/chunking/late_chunking.py",
        "src/enhancement/llm_contextualizer.py",
        "scripts/process_bible.py",
        "app.py"
    ]
    
    print("ğŸ“ Checking project structure...")
    missing_files = []
    for file_path in required_files:
        full_path = project_root / file_path
        if full_path.exists():
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path}")
            missing_files.append(file_path)
    
    if missing_files:
        print(f"\nâš ï¸  Missing files: {missing_files}")
        return False
    
    # Check raw data
    print(f"\nğŸ“– Checking Bible data...")
    raw_data_path = project_root / "data/raw"
    bible_files = list(raw_data_path.glob("*.txt")) + list(raw_data_path.glob("*.json"))
    
    if not bible_files:
        print("âŒ No Bible files found in data/raw/")
        return False
    
    print(f"âœ… Found {len(bible_files)} Bible files")
    
    # Analyze Bible structure
    parser = EthiopianBibleParser()
    
    for bible_file in bible_files:
        print(f"\nğŸ“Š Analyzing {bible_file.name}...")
        analysis = parser.analyze_bible_structure(str(bible_file))
        
        print(f"Books found: {analysis['total_books_found']}/72 ({analysis['coverage']:.1f}%)")
        
        if analysis['total_books_found'] > 50:  # Good coverage
            print("âœ… Good book coverage detected")
            
            # Extract all books
            print("ğŸ“š Extracting all books...")
            extracted_books = parser.extract_all_books(str(bible_file))
            
            # Save structured data
            output_file = PROCESSED_DATA_DIR / f"structured_{bible_file.stem}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(extracted_books, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Structured data saved to {output_file}")
            
            # Count chapters and verses
            total_chapters = sum(len(chapters) for chapters in extracted_books.values())
            print(f"ğŸ“– Total books extracted: {len(extracted_books)}")
            print(f"ğŸ“„ Total chapters: {total_chapters}")
            
            return True
        else:
            print("âš ï¸  Low book coverage - may need better parsing")
    
    return False

async def test_embedding_pipeline():
    """Test the complete embedding pipeline"""
    
    print("\nğŸ§  Testing Embedding Pipeline...")
    
    # Import required modules
    try:
        from src.preprocessing.amharic_cleaner import amharic_cleaner
        from src.chunking.late_chunking import late_chunking_embedder, ChunkInfo
        print("âœ… All modules imported successfully")
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return False
    
    # Test with sample text
    sample_text = "áˆ˜áŒ€áˆ˜áˆªá‹« áˆ‹á‹­ áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­ áˆ°áˆ›á‹­áŠ•áŠ“ áˆá‹µáˆ­áŠ• áˆáŒ áˆ¨á¢ áˆá‹µáˆ­áˆ á‰£á‹¶áŠ“ áŠ­á‰ áŠá‰ áˆ¨á‰½á¢"
    
    # Test cleaning
    cleaned = amharic_cleaner.preprocess_for_embeddings(sample_text)
    print(f"âœ… Text cleaning: '{sample_text[:30]}...' â†’ '{cleaned[:30]}...'")
    
    # Test chunk creation
    chunks = [
        ChunkInfo(
            text="áˆ˜áŒ€áˆ˜áˆªá‹« áˆ‹á‹­ áŠ¥áŒá‹šáŠ á‰¥áˆ”áˆ­ áˆ°áˆ›á‹­áŠ•áŠ“ áˆá‹µáˆ­áŠ• áˆáŒ áˆ¨á¢",
            start_pos=0,
            end_pos=40,
            book="Genesis",
            chapter=1,
            verse_range=(1, 1)
        )
    ]
    
    # Test embedding (traditional method first for verification)
    try:
        traditional_embeddings = late_chunking_embedder.embed_traditional([chunk.text for chunk in chunks])
        print(f"âœ… Traditional embeddings: Shape {traditional_embeddings[0].shape}")
        
        # Test Late Chunking
        late_chunking_results = late_chunking_embedder.embed_with_late_chunking(sample_text, chunks)
        print(f"âœ… Late Chunking embeddings: {len(late_chunking_results)} chunks created")
        
        return True
        
    except Exception as e:
        print(f"âŒ Embedding error: {e}")
        return False

def create_missing_directories():
    """Create any missing directories"""
    
    dirs = [
        "data/processed", "data/chunks", "data/embeddings",
        "src/preprocessing", "src/chunking", "src/enhancement", 
        "src/embeddings", "src/retrieval", "scripts", "tests", "notebooks"
    ]
    
    project_root = Path("/Users/mekdesyared/Embedding/amharic-bible-embeddings")
    
    for dir_name in dirs:
        dir_path = project_root / dir_name
        dir_path.mkdir(parents=True, exist_ok=True)
        
        # Create __init__.py files for Python packages
        if dir_name.startswith("src/"):
            init_file = dir_path / "__init__.py"
            if not init_file.exists():
                init_file.touch()

async def main():
    """Main verification function"""
    
    print("ğŸš€ Amharic Bible Embeddings - Complete Verification")
    print("=" * 60)
    
    # Create missing directories
    create_missing_directories()
    
    # Verify project structure
    structure_ok = verify_implementation()
    
    if not structure_ok:
        print("\nâŒ Project structure verification failed")
        return 1
    
    # Test embedding pipeline
    pipeline_ok = await test_embedding_pipeline()
    
    if not pipeline_ok:
        print("\nâŒ Embedding pipeline test failed")
        return 1
    
    print("\n" + "=" * 60)
    print("âœ… ALL VERIFICATIONS PASSED!")
    print("\nğŸ“‹ Next Steps:")
    print("1. Configure your API keys in .env")
    print("2. Run: python scripts/process_bible.py")
    print("3. Start web app: streamlit run app.py")
    print("\nğŸ¯ Ready to embed all 72 books of the Ethiopian Bible!")
    
    return 0

if __name__ == "__main__":
    import asyncio
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
